{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib2\n",
    "import re\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "request = urllib2.Request('http://boston.menupages.com/restaurants/all-areas/all-neighborhoods/all-cuisines/' + str(1))\n",
    "request.add_header('User-agent', 'Mozilla/5.0 (Linux i686)')\n",
    "\n",
    "response = urllib2.urlopen(request)\n",
    "\n",
    "soup = BeautifulSoup(response.read())\n",
    "\n",
    "num_restaurants = int(soup.find('strong').text)\n",
    "num_pages = int(math.ceil(num_restaurants/100.0))\n",
    "\n",
    "base_url = 'http://boston.menupages.com'\n",
    "\n",
    "total_names = []\n",
    "total_links = []\n",
    "total_prices = []\n",
    "total_addresses = []\n",
    "total_longitude = []\n",
    "total_latitude = []\n",
    "\n",
    "for num_page in range(num_pages):\n",
    "    \n",
    "    page_request = urllib2.Request('http://boston.menupages.com/restaurants/all-areas/all-neighborhoods/all-cuisines/' + str(num_page + 1))\n",
    "    page_request.add_header('User-agent', 'Mozilla/5.0 (Linux i686)')\n",
    "\n",
    "    page_response = urllib2.urlopen(page_request).read()\n",
    "\n",
    "    page_soup = BeautifulSoup(page_response)\n",
    "\n",
    "    places = page_soup.find_all(class_ = 'link')\n",
    "\n",
    "    for the_place in places:\n",
    "        total_names.append(re.sub('.*</span>|</a>', '', str(the_place)))\n",
    "        total_links.append(base_url + the_place.get('href') + 'menu')\n",
    "    \n",
    "    raw_prices = page_soup.findAll(True, {'class':['price1', 'price2', 'price3', 'price4', 'price5']})\n",
    "\n",
    "    for the_price in raw_prices:\n",
    "        total_prices.append(the_price.text)\n",
    "    \n",
    "    longitude = re.findall(\"data\\[[0-9]+\\]\\[\\'longitude\\'\\] = \\\"(.*)\\\";\", str(page_soup))\n",
    "    longitude = [float(i) for i in longitude]\n",
    "\n",
    "    latitude = re.findall(\"data\\[[0-9]+\\]\\[\\'latitude\\'\\] = \\\"(.*)\\\";\", str(page_soup))\n",
    "    latitude = [float(i) for i in latitude]\n",
    "\n",
    "    address = re.findall(\"data\\[[0-9]+\\]\\[\\'address1\\'\\] = \\\"(.*)\\\";\", str(page_soup))\n",
    "\n",
    "    for index in range(len(places)):\n",
    "        total_longitude.append(longitude[index])\n",
    "        total_latitude.append(latitude[index])\n",
    "        total_addresses.append(address[index])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({ 'name' : total_names,\n",
    "                    'link' : total_links,\n",
    "                    'price': total_prices,\n",
    "                    'address' : total_addresses,\n",
    "                    'longitude' : total_longitude,\n",
    "                    'latitude' : total_latitude})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://boston.menupages.com/restaurants/o-yummy-cuisine/menu\n"
     ]
    }
   ],
   "source": [
    "print df['link'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lobster ravioli poached lobster tail crispy leeks saffron lobster cream sauce deconstructed tuna maki lotus root tobiko nori powder ponzu foam spicy tuna sauce seasonal soup chef's seasonal offering pork belly confit savoy cabbage pickled mustard seeds rosemary apple puree candied cranberries cranberry jus harvest salad figs asian pears red endive arugula goat cheese marcona almond vinaigrette duo of beef tea smoked beef korean beef tartare quail egg watercress salad mixed greens salad seasonal greens shaved carrots cucumber cherry tomatoes pinot grigio vinaigrette local seared scallops shimeji mushrooms cucumber daikon radish dashi broth bacon wrapped pork loin applewood bacon roasted brussels leaves parsnip puree cranberry puree chamomile powder apple cider gelee shaved marcona almonds butter poached lobster braised leeks baby beets amaranth caviar beurre blanc verjus emulsion slow roasted filet mille feuilles potatoes roasted marrow bone baby fennel carrots huckleberry jus pasta alla carbonara house made black pepper fettuccine pancetta lardon chanterelles truffle poached duck egg local cod rainbow chard cherry tomatoes wellfleet clams pickled chard stems white wine nage duo of chicken confit leg thigh crispy statler breast collard greens truffle mac cheese red wine sauce frutti di mare house made linguini shrimp scallop clams oven roasted tomatoes basil lobster sauce braised lamb shank oven roasted tomato couscous parmesan foam crispy basil leaves pasta alla bolognese house made pappardelle bolognese ragu ricotta salata oven roasted tomato couscous roasted brussels sprouts winter vegetables truffle mac cheese shrimp cocktail old bay mustard aioli jalapeno cocktail sauce local oysters mignonette sauce local clams mint chili sauce jonah crab claws old bay mustard aioli jalapeno cocktail sauce seafood platter tuna tartare avocado yuzo puree mango cucumber taro root chip chili sauce frog legs waffles crispy frog legs tarragon waffles cippolini onion cognac sauce short rib sliders braised short rib sharp cheddar crispy onion horseradish sauce pommes frites trio rosemary garlic truffle parmesan fine herb pink peppercorn sea salt hummus toasted pine nuts paprika oil parsley pita chips marinated olives cheese italian olive mix aged pecorino almonds grilled baguette spring rolls pickled carrots napa cabbage scallions vermicelli chili sauce chicken kebab garlic lemon marinade roasted potato coins house burger sharp cheddar crispy leeks bibb lettuce tomato truffle aioli rosemary garlic pommes frites bourbon chicken boneless chicken bourbon sesame ginger glaze shrimp cocktail old bay mustard aioli jalapeno cocktail sauce local oysters mignonette sauce local clams mint chili sauce jonah crab claws old bay mustard aioli jalapeno cocktail sauce seafood platter cheese plate assortment of local cheeses with accompaniments charcuterie sopressata prosciutto di parma coppa charcuterie plate assortment of charcuterie with accompaniments margherita mozzarella basil tomato fig prosciutto black mission figs caramelized onions prosciutto blue brie cheese truffle mushroom wild mushroom truffles baby arugula social house pour featuring pretty things jack d'or american saison ale allagash white belgian style wheat ale dogfish head min ipa india pale ale stella artois european pale lager bud light thomas hooker blonde ale franziskaner weissbier ommegang hennepin saison samuel adams seasonal anchor steam beer stone pale ale chimay \"blue\" smuttynose old brown dog otter creek alpine ipa samuel smith taddy porter estrella damm inedit created by chef ferran adria of elbulli restaurant clausthaler non alcoholic non alcoholic pear vodka fig puree brown sugar lemon drunken apple bourbon caramel liqueur cinnamon simple syrup lemon apple juice it's o'clock somewhere tequila lillet maple syrup blood orange soda lime the dirty blonde citron vodka st germain thomas hooker blonde ae lemon new year's resolution champagne poive liqueur pama liqueur cranberries salaria bombay sapphire st germain lemon infused bitters sugar spice tequila kumquats togarashi spice agave nectar citrus mai chai white rum bailey's chai tea pom o tini absolute mandrin vodka cointreau basil pomegranate syrup orange juice agave root beer float vanilla vodka root liqueur bailey's chocolate bitters nino franco prosecco italy roederer estate brut anderson valley ca cave de lugny macon france merryvale \"starmont\" napa ca pascal jolivet \"attitude\" sancerre france villa maria marlborough new zealand caposaldo pinot grigio veneto italy trimbach pinot gris alsace france s a pr m essence germany burgans albarino rias baixas huber \"hugo\" gr ner veltliner traisental austria helfrich gewurztraminer alsace france angeline russian river valley ca balletto russian river valley ca hands columbia valley wa masi \"passo doble\" mendoza argentina melini \"borghi d'elsa\" san lorenzo italy genesis columbia valley wa oberon napa ca chateau di pizay beaujolais france l'independence bordeaux france chateau du trignon cotes du rhone france\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords # Import the stop word list\n",
    "\n",
    "def menu_to_words(html_menu):\n",
    "    \n",
    "    # Function to convert a menupages link to a list of food words\n",
    "    # The input is a single string (html menu pages)\n",
    "    # The output is a single string (preprocessed menu)\n",
    "    \n",
    "    # 1. Scrape menupages page\n",
    "    \n",
    "    menu_request = urllib2.Request(html_menu)\n",
    "    menu_request.add_header('User-agent', 'Mozilla/5.0 (Linux i686)')\n",
    "    menu_response = urllib2.urlopen(menu_request).read()\n",
    "    menu_soup = BeautifulSoup(menu_response)\n",
    "    all_food = menu_soup.find_all('th')\n",
    "\n",
    "    # 0 to 6 is always dollar amounts, so I can skip them\n",
    "\n",
    "    the_food = []\n",
    "    for the_line in range(7, len(all_food)):\n",
    "        the_food.append(all_food[the_line].text)\n",
    "    \n",
    "    the_menu = ' '.join(the_food)\n",
    "    \n",
    "    # 2. Remove non-letters\n",
    "    \n",
    "    the_menu_letters = re.sub(\"[^a-zA-Z\\'\\\"]\", \" \", the_menu)\n",
    "    \n",
    "    # 3. Convert to lower case, split into individual words\n",
    "    \n",
    "    lower_case = the_menu_letters.lower()\n",
    "    words = lower_case.split()\n",
    "    \n",
    "    # 4. Remove stopwords (add later as an optional argument)\n",
    "    \n",
    "    words = [w for w in words if not w in stopwords.words(\"english\")]\n",
    "    \n",
    "    # 5. Join the words\n",
    "    \n",
    "    return(' '.join(words)) \n",
    "    \n",
    "\n",
    "    \n",
    "# Now need to construct the word list in python, then I should probably re-factorize\n",
    "\n",
    "menu_request = urllib2.Request(df['link'][0])\n",
    "menu_request.add_header('User-agent', 'Mozilla/5.0 (Linux i686)')\n",
    "\n",
    "menu_response = urllib2.urlopen(menu_request).read()\n",
    "\n",
    "menu_soup = BeautifulSoup(menu_response)\n",
    "\n",
    "#print menu_soup\n",
    "\n",
    "all_food = menu_soup.find_all('th')\n",
    "\n",
    "# 0 to 6 is always dollar amounts, so I can skip them\n",
    "\n",
    "the_food = []\n",
    "\n",
    "for the_line in range(7, len(all_food)):\n",
    "    the_food.append(all_food[the_line].text)\n",
    "\n",
    "the_menu = ' '.join(the_food)\n",
    "\n",
    "the_menu_letters = re.sub(\"[^a-zA-Z\\'\\\"]\", \" \", the_menu)\n",
    "\n",
    "lower_case = the_menu_letters.lower()\n",
    "\n",
    "words = lower_case.split()\n",
    "\n",
    "#words = [w for w in words if not w in stopwords.words(\"english\")]\n",
    "print ' '.join(words)\n",
    "print menu_to_words(html_menu)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating the bag of words...\n",
      "\n",
      "[[ 1  2  1  1  1  2  1  5  1  2  5  2  1  1  2  1  2  1  1  1  1  1  4  1\n",
      "   1  1  2  1  2  1  1  1  3  2  1  2  1  1  4  4  1  3  2  1  1  1  1  1\n",
      "   2  2  1  3  1  2  2  1  1  1  1  1  3  3  1  1  1  2  2  1  1  1  1  1\n",
      "   5  2  1  1  1  1  1  3  1  1  2  1  1  1  3  2  2  2  6  1  2  2  4  4\n",
      "   1  1  1  1  1  1  1  1  1  4  1  2  1  6  1  1  1  1  1  2  2  1  1  2\n",
      "   2  2  2  1  1  1  6  3  1  1  1  1  1  3  1  1  1  1  1  2  1  2  2  1\n",
      "   1  1  1  1  1  1  1  1  1  1  1  1  2  2  1  1  1  2  7  1  1  2  2  1\n",
      "   3  1  1  2  1  1  1  1  1  1  3  2  1  1  1  1  1  1  1  1  2  1  5  1\n",
      "   1  1  1  1  1  1  1  2  1  1  3  1  4  1  2  2  2  1  1  1  1  1  1  2\n",
      "   3  1  2  5  1  1  1  1  1  4  5  7  1  1  1  1  2  1  3  1  1  1  1  1\n",
      "   2  1  1  1  1  1  1  1  1  1  1  1  2  1  1  2  1  1  1  1  2  1  5  1\n",
      "   3  1  1  2  1  2  1  1  1  1  1  5  1  1  1  2  1  1  2  1  3  2  3  1\n",
      "   1  1  1  1  2  1  1  1  1  2  1  1  1  1  1  3  1  1  3  1  1  2  2  3\n",
      "   1  1  1  2  1  2  1  1  1  1  2  1  1  3  1  5  1  1  1  1  1  2  1  1\n",
      "   1  1  2  1  2  8  1  1  4  3  1  2  1  2  3  1  1  1  2  1  1  1 16  1\n",
      "   1  1  1  1  2  1  4  1  1  1  2  2  1  2  3  1  1  1  1  1  1  1  1  1\n",
      "   1  1  2  1  1  1  2  1  1  1  1  1  1  1  2  3  1  1  1  1  2  2  2  1\n",
      "   1  2  1  1  1  1  4  3  1  1  1  1  6  1  3  5  1  1  1  1  1  1  1  2\n",
      "   4  2  2  1  1  1  1  3  1  2  1  1  1  1  1]\n",
      " [ 1  2  1  1  1  2  1  5  1  2  5  2  1  1  2  1  2  1  1  1  1  1  4  1\n",
      "   1  1  2  1  2  1  1  1  3  2  1  2  1  1  4  4  1  3  2  1  1  1  1  1\n",
      "   2  2  1  3  1  2  2  1  1  1  1  1  3  3  1  1  1  2  2  1  1  1  1  1\n",
      "   5  2  1  1  1  1  1  3  1  1  2  1  1  1  3  2  2  2  6  1  2  2  4  4\n",
      "   1  1  1  1  1  1  1  1  1  4  1  2  1  6  1  1  1  1  1  2  2  1  1  2\n",
      "   2  2  2  1  1  1  6  3  1  1  1  1  1  3  1  1  1  1  1  2  1  2  2  1\n",
      "   1  1  1  1  1  1  1  1  1  1  1  1  2  2  1  1  1  2  7  1  1  2  2  1\n",
      "   3  1  1  2  1  1  1  1  1  1  3  2  1  1  1  1  1  1  1  1  2  1  5  1\n",
      "   1  1  1  1  1  1  1  2  1  1  3  1  4  1  2  2  2  1  1  1  1  1  1  2\n",
      "   3  1  2  5  1  1  1  1  1  4  5  7  1  1  1  1  2  1  3  1  1  1  1  1\n",
      "   2  1  1  1  1  1  1  1  1  1  1  1  2  1  1  2  1  1  1  1  2  1  5  1\n",
      "   3  1  1  2  1  2  1  1  1  1  1  5  1  1  1  2  1  1  2  1  3  2  3  1\n",
      "   1  1  1  1  2  1  1  1  1  2  1  1  1  1  1  3  1  1  3  1  1  2  2  3\n",
      "   1  1  1  2  1  2  1  1  1  1  2  1  1  3  1  5  1  1  1  1  1  2  1  1\n",
      "   1  1  2  1  2  8  1  1  4  3  1  2  1  2  3  1  1  1  2  1  1  1 16  1\n",
      "   1  1  1  1  2  1  4  1  1  1  2  2  1  2  3  1  1  1  1  1  1  1  1  1\n",
      "   1  1  2  1  1  1  2  1  1  1  1  1  1  1  2  3  1  1  1  1  2  2  2  1\n",
      "   1  2  1  1  1  1  4  3  1  1  1  1  6  1  3  5  1  1  1  1  1  1  1  2\n",
      "   4  2  2  1  1  1  1  3  1  2  1  1  1  1  1]]\n"
     ]
    }
   ],
   "source": [
    "foo = [' '.join(words), ' '.join(words)]\n",
    "\n",
    "print \"Creating the bag of words...\\n\"\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Initialize the \"CountVectorizer\" object, which is scikit-learn's\n",
    "# bag of words tool.  \n",
    "vectorizer = CountVectorizer(analyzer = \"word\",   \\\n",
    "                             tokenizer = None,    \\\n",
    "                             preprocessor = None, \\\n",
    "                             stop_words = None,   \\\n",
    "                             max_features = 5000) \n",
    "\n",
    "# fit_transform() does two functions: First, it fits the model\n",
    "# and learns the vocabulary; second, it transforms our training data\n",
    "# into feature vectors. The input to fit_transform should be a list of \n",
    "# strings.\n",
    "train_data_features = vectorizer.fit_transform(foo)\n",
    "\n",
    "# Numpy arrays are easy to work with, so convert the result to an \n",
    "# array\n",
    "train_data_features = train_data_features.toarray()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
